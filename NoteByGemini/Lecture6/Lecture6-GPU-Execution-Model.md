### 模板A: 核心概念

#### 1. 这是什么？(What is it?)
**GPU 执行模型 (GPU Execution Model)** 是一个抽象层, 它定义了我们如何组织并行任务, 并将其映射到 GPU 硬件上执行. 以 NVIDIA 的 CUDA 为例, 该模型采用了一种层次化的结构, 让我们能够以结构化的方式来思考和管理成千上万个并行线程. 

#### 2. 为什么重要？(Why is it important?)
这个模型为我们提供了一种心智模型(mental model), 使我们能够编写出可以扩展到任意规模并行度的代码, 而无需关心具体的硬件细节, 如 SM 的确切数量. 它将复杂的硬件调度问题简化为对**网格 (Grid)**、**线程块 (Block)** 和 **线程 (Thread)** 的逻辑组织. 理解这个模型是编写任何 GPU Kernel(无论是用 **[CUDA](./Lecture6-CUDA.md)** 还是 **[Triton](./Lecture6-Triton.md)**)的前提. 

#### 3. 它是如何工作的？(How does it work?)
GPU 执行模型包含三个核心层次:

*   **线程 (Thread)**:
    *   执行的基本单位, 通常负责处理数据的一个最小单元(例如, 一个像素、一个向量元素). 
    *   每个线程都有一个唯一的 `threadIdx`, 用于在线程块内标识自己. 
    *   所有线程并行执行相同的代码, 这段代码被称为 **Kernel**. 

*   **线程块 (Thread Block)**:
    *   一组线程的集合, 它们可以相互协作. 一个线程块会被完整地调度到**一个** **[SM (流式多处理器)](./Lecture6-GPU-Architecture.md)** 上执行. 
    *   **关键特性**:同一线程块内的所有线程共享一块高速的**[共享内存 (Shared Memory)](./Lecture6-Shared-Memory.md)**, 并可以通过同步原语 (`__syncthreads()`) 进行协调. 这使得它们可以高效地交换数据, 是实现高性能归约、卷积和矩阵乘法等算法的基础. 
    *   线程块的存在是为了利用数据局部性:将需要共享数据的计算任务组织在同一个块中. 
    *   每个线程块有一个唯一的 `blockIdx`, 用于在网格内标识自己. 

*   **网格 (Grid)**:
    *   一次 Kernel 启动 (launch) 所创建的所有线程块的集合. 
    *   一个网格代表了需要解决的整个问题. 例如, 要处理一张 1024x1024 的图片, 可以启动一个由多个 16x16 的线程块组成的网格. 
    *   **重要限制**:不同线程块之间**不能**直接通信或同步. 它们被认为是相互独立的, 这保证了程序的可扩展性——无论 GPU 有多少个 SM, 程序都能正确执行. 

*   **线程束 (Warp)**:
    *   这是一个硬件层面的概念, 但在性能调优时非常重要. SM 以 32 个线程为一组来执行指令, 这一组被称为一个 Warp. 
    *   Warp 内的线程以 SIMD (Single Instruction, Multiple Data) 的方式执行, 即所有 32 个线程在同一时刻执行完全相同的指令. 
    *   如果 Warp 内的线程执行了不同的代码路径(例如, 由于 `if-else` 分支), 就会发生“分支发散” (branch divergence), 导致部分线程被闲置, 从而降低性能. 

#### 4. 关键要点 (Key Takeaways)
*   **层次结构**:Grid > Block > Thread. 这是组织并行任务的基本框架. 
*   **协作单位**:**线程块**是协作的核心. 需要数据共享和同步的任务必须在同一个线程块内完成. 
*   **独立性**:**线程块之间相互独立**, 这保证了代码的可扩展性. 
*   **编程心智模型**:我们编写的是单个线程执行的 Kernel 代码, 但通过 `blockIdx` 和 `threadIdx`, 每个线程可以计算出自己的全局 ID, 从而处理不同部分的数据. 