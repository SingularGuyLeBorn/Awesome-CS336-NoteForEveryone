### 概念: 模型内存计算 (Model Memory Calculation)

#### 1. 核心定义

模型内存计算指的是在训练或推理深度学习模型时, 对 GPU (或其它加速器) 显存占用的分析和估算. 精确地计算内存占用对于规划硬件资源、设置批次大小以及选择合适的并行策略至关重要. 内存不足 (Out of Memory, OOM) 是从业者最常遇到的错误之一.

#### 2. 训练过程中的主要内存组成部分

在模型训练期间, GPU 内存主要被以下几个部分占用:

1.  **模型参数 (Model Parameters)**:
    - 这是模型本身的权重和偏置.
    - 内存占用 = `参数数量 × 每个参数的字节数`.
    - 例如, 一个 7B (70 亿) 参数的模型, 如果以 FP16/BF16 (2 字节) 格式存储, 则参数本身占用 `7e9 * 2 = 14 GB`.

2.  **梯度 (Gradients)**:
    - 在反向传播过程中, 会为每一个模型参数计算一个梯度.
    - 梯度的数量与参数数量相同.
    - 内存占用通常也与参数相同. 如果使用 FP16/BF16, 则同样为 `14 GB`.

3.  **优化器状态 (Optimizer States)**:
    - 这是内存消耗的大头, 尤其在使用 **[Adam](./Lecture7-Adam-Optimizer.md)** 或 AdamW 等自适应优化器时.
    - 对于每个参数, Adam 需要存储:
        - **一阶矩 (Momentum)**: 通常是 FP32 (4 字节).
        - **二阶矩 (Variance)**: 通常是 FP32 (4 字节).
    - 在混合精度训练中, 为了精确更新, 通常还会保留一份 FP32 (4 字节) 的**主权重 (Master Weights)**.
    - 总计: 每个参数需要 `4 + 4 = 8` 字节 (如果主权重由优化器管理, 有时可达 12 字节).
    - 对于 7B 模型, 优化器状态占用 `7e9 * 8 = 56 GB`.

4.  **激活值 (Activations)**:
    - 这是前向传播过程中产生的中间结果, 需要存储以备反向传播使用.
    - 激活内存的计算较为复杂, 依赖于**批次大小 (B)**, **序列长度 (S)**, **隐藏层维度 (H)** 和**模型层数 (L)**.
    - 一个粗略的估算公式 (对于 Transformer) 为: `内存 ≈ B × S × H × L × (一些常数)`.
    - 激活内存是动态的, 在前向传播时增长, 在反向传播时减少. 其峰值是决定是否 OOM 的关键因素.
    - **[激活重计算](./Lecture7-Activation-Recomputation.md)**是专门用于降低这部分内存的技术.

#### 3. 朴素数据并行下的内存估算示例

假设一个 7B 参数的模型, 使用 AdamW 优化器, 以 BF16 格式进行训练. 每个 GPU 上需要的内存大约为:
- **参数**: 7B × 2 字节 = 14 GB
- **梯度**: 7B × 2 字节 = 14 GB
- **优化器状态** (假设 FP32): 7B × (4 + 4) 字节 = 56 GB
- **总计 (不含激活)**: 14 + 14 + 56 = **84 GB**.

这个估算清晰地表明:
- 优化器状态是主要的内存瓶颈.
- 即使是顶级的 80GB A100/H100 GPU, 在不进行任何内存优化的情况下, 也难以容纳一个 7B 模型的完整训练状态 (这还没算上激活值!).
- 这也解释了为什么**[ZeRO](./Lecture7-ZeRO.md)** 和 **[FSDP](./Lecture7-FSDP.md)** 等分片技术对于训练大模型是不可或缺的. 它们通过将梯度和优化器状态 (甚至参数) 分摊到多个 GPU 上, 极大地降低了单个 GPU 的内存压力.