### 概念: 模型并行 (Model Parallelism)

#### 1. 核心定义

模型并行是一种分布式训练策略, 其核心思想是将**单个巨大的模型本身**进行切分, 模型的不同部分被放置在不同的计算设备 (GPU) 上. 这与**[数据并行](./Lecture7-Data-Parallelism.md)**形成鲜明对比, 后者是在每个设备上都保留完整的模型副本. 当模型大到无法装入单个 GPU 内存时, 模型并行就成为了一种必要的选择.

#### 2. 模型并行的主要类型

模型切分的方式主要有两种, 对应着两种主流的模型并行技术:

- **[流水线并行 (Pipeline Parallelism)](./Lecture7-Pipeline-Parallelism.md)**:
    - **切分维度**: **深度 (Depth)**.
    - **工作原理**: 将神经网络按**层 (layer)**进行切分. 例如, 一个 48 层的模型可以被切分到 4 个 GPU 上, 每个 GPU 负责执行 12 个连续的层.
    - **数据流**: 数据在一个 GPU 上完成其负责的层计算后, 产生的激活值 (activations) 会被传递给下一个 GPU, 作为其输入的开始. 这个过程像流水线一样依次进行. 在反向传播时, 梯度则以相反的方向传递.
    - **通信内容**: 设备间主要传递的是**激活值**和**梯度**.

- **[张量并行 (Tensor Parallelism)](./Lecture7-Tensor-Parallelism.md)**:
    - **切分维度**: **宽度 (Width)**.
    - **工作原理**: 在更细的粒度上进行切分, 针对模型中的单个大算子 (通常是矩阵乘法) 进行并行化. 例如, 一个大的权重矩阵 `W` 可以被按列切分为 `[W1, W2]`, 并分给两个 GPU. 当输入 `X` 到来时, 两个 GPU 分别计算 `X*W1` 和 `X*W2`, 然后通过一次**[集体通信操作](./Lecture7-Collective-Communication.md)** (如 All-Reduce 或 All-Gather) 将结果合并.
    - **通信内容**: 通信内容取决于具体的实现, 但通常也涉及激活值的同步和聚合.

#### 3. 核心挑战

- **负载均衡**: 如何切分模型以确保每个 GPU 的计算负载大致相等, 避免某些 GPU 成为瓶颈.
- **通信开销**: 模型并行引入了新的通信需求 (传递激活值). 如何最小化这些通信, 并将其与计算重叠, 是性能优化的关键.
- **设备空闲 (Bubble)**: 特别是在**[流水线并行](./Lecture7-Pipeline-Parallelism.md)**中, 由于计算的依赖关系, 在流水线的启动和排空阶段, 很多 GPU 会处于空闲状态, 造成资源浪费. 这被称为**[流水线气泡](./Lecture7-Pipeline-Bubble.md)**.

#### 4. 与数据并行的关系

模型并行和数据并行是正交的, 它们可以而且经常被**组合使用**. 在一个典型的**[3D 并行](./Lecture7-3D-Parallelism.md)**设置中:
- **张量并行**用于节点内部, 利用高速互连来切分单个大层.
- **流水线并行**用于跨节点, 将模型的不同阶段分配到不同的机器组上.
- **数据并行**则在整个流水线的副本上应用, 以增加全局批次大小, 提升整体吞吐量.

总而言之, 模型并行是解决"模型装不下"这一根本性问题的关键技术, 是训练千亿乃至万亿级别参数模型的基石.