### 概念: 流水线并行 (Pipeline Parallelism)

#### 1. 核心定义

流水线并行是一种**[模型并行](./Lecture7-Model-Parallelism.md)**技术, 它通过将神经网络按**深度** (即按层) 切分, 并将不同的层块 (stages) 分配给不同的计算设备 (GPU) 来实现并行化. 数据像在工厂流水线上一样, 依次流经各个设备, 完成整个模型的计算.

#### 2. 朴素流水线与“气泡”问题

- **工作流程**:
    1.  GPU 0 执行模型的前几层 (Stage 0).
    2.  GPU 0 将其输出的激活值发送给 GPU 1.
    3.  GPU 1 接收到激活值后, 开始执行模型的下一批层 (Stage 1).
    4.  ...这个过程一直持续到最后一个 GPU (Stage N-1) 完成前向传播.
    5.  然后, 反向传播以相反的顺序开始.

- **[流水线气泡 (Pipeline Bubble)](./Lecture7-Pipeline-Bubble.md)**:
    在上述朴素流程中, 当 GPU 0 在工作时, 所有其他 GPU (1 到 N-1) 都在空闲等待. 当 GPU 1 工作时, GPU 0 和 GPU 2 到 N-1 又可能空闲. 这种由于计算依赖性导致的设备空闲时间被称为“流水线气泡”. 在一个批次的处理过程中, 这个气泡会非常大, 导致 GPU 利用率极低, 接近 `1/N`, 几乎完全抵消了并行化带来的好处.

#### 3. 优化: 微批次流水线 (Micro-batch Pipelining)

为了解决气泡问题, 现代流水线并行采用微批次 (micro-batch) 技术.

- **工作原理**:
    1.  将一个大的全局批次 (global batch) 切分成多个小的微批次.
    2.  GPU 0 处理完第一个微批次后, 立即将其激活值发送给 GPU 1, **然后马上开始处理第二个微批次**, 而不是等待整个全局批次完成.
    3.  这样, GPU 0 和 GPU 1 就可以**同时工作**, 只是处理的是不同的微批次.
    4.  通过让所有 GPU 并行处理不同的微批次, 计算和通信得以重叠, 显著减小了流水线气泡.

- **气泡大小与微批次数的关系**:
    流水线开销与有效计算时间的比率大致为 `(阶段数 - 1) / 微批次数`. 这意味着, **微批次的数量越多 (即全局批次越大), 流水线气泡就越小, 效率越高**.

#### 4. 优缺点与适用场景

- **优点**:
    - **内存节省**: 它不仅分片了参数, 还自然地分片了激活值 (每个 GPU 只需存储其负责的层的激活), 内存效率很高.
    - **通信模式简单**: 通常是点对点 (point-to-point) 通信, 只在相邻的 GPU 之间传递激活值. 相比于需要 All-Reduce 的**[张量并行](./Lecture7-Tensor-Parallelism.md)**, 它对网络拓扑的要求较低.

- **缺点**:
    - **存在气泡**: 即使使用微批次, 气泡也无法完全消除, 仍然存在效率损失.
    - **消耗批次大小资源**: 高效的流水线并行强依赖于大的全局批次, 这与其他并行策略 (如数据并行) 形成了资源竞争.
    - **实现复杂**: 管理微批次的调度、梯度累积和参数更新等逻辑非常复杂. 高级优化如 "Zero-Bubble" 或 "Interleaved" 流水线更是需要深入修改自动微分系统.

- **适用场景**:
    由于其对带宽要求相对较低, 流水线并行通常被用于**跨节点 (inter-node)**的并行化, 特别是在网络连接速度成为瓶颈的场景下. 它是**[3D 并行](./Lecture7-3D-Parallelism.md)**策略中负责在机器间分割超大模型的核心组件.