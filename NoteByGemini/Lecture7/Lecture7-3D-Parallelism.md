### 概念: 3D 并行 (3D Parallelism)

#### 1. 核心定义

3D 并行是一种综合性的、先进的分布式训练框架, 它通过**同时组合**三种不同维度(或类型)的并行策略, 来最大化大规模模型训练的效率和可扩展性. 这三种维度通常是:
1.  **[数据并行 (Data Parallelism)](./Lecture7-Data-Parallelism.md)**
2.  **[流水线并行 (Pipeline Parallelism)](./Lecture7-Pipeline-Parallelism.md)**
3.  **[张量并行 (Tensor Parallelism)](./Lecture7-Tensor-Parallelism.md)**

这种多维度的组合允许训练架构师根据硬件特性和模型需求, 对计算、内存和通信进行精细的权衡和优化.

#### 2. 三个维度的分工与协同

在一个典型的 3D 并行设置中, `N` 个 GPU 的集群会被逻辑地组织成一个 `D x P x T` 的三维网格, 其中 `N = D * P * T`.

- **张量并行 (T - Tensor Parallelism)**:
    - **作用域**: **最内层**, 通常在单个服务器节点内部.
    - **职责**: 将单个大模型层 (特别是矩阵乘法) 切分到 `T` 个 GPU 上.
    - **原因**: 张量并行对网络带宽和延迟要求最高, 必须利用节点内部的 NVLink 等高速互连. 它的路数 (如 8 路) 通常受限于单个节点的 GPU 数量.

- **流水线并行 (P - Pipeline Parallelism)**:
    - **作用域**: **中间层**, 通常跨越多个服务器节点.
    - **职责**: 将整个模型的层序列切分成 `P` 个阶段 (stages), 每个阶段由一组 `T` 个 GPU (一个张量并行组) 负责.
    - **原因**: 流水线并行主要用于解决模型大到无法装入一个张量并行组内存的问题. 它的通信量相对较小 (只传递激活值), 更能容忍跨节点网络的较高延迟.

- **数据并行 (D - Data Parallelism)**:
    - **作用域**: **最外层**, 在整个模型副本上进行.
    - **职责**: 将整个已经经过张量和流水线并行切分的模型复制 `D` 份. 每个副本处理全局批次数据的一部分.
    - **原因**: 数据并行是扩展总计算吞吐量的主要手段. 它的通信 (梯度 All-Reduce) 可以在较低带宽的网络上进行, 并且可以与计算重叠, 因此最适合用于大规模扩展到整个集群.

#### 3. 部署的经验法则 (Rule of Thumb)

部署 3D 并行时, 通常遵循一个清晰的优先级顺序:

1.  **目标一: 装下模型 (Fit the model in memory)**
    - **Step 1**: 首先应用**张量并行**, 直到达到节点内 GPU 数量的上限 (通常是 8). 这是最优先的, 因为它能有效减少每层的内存占用.
    - **Step 2**: 如果模型仍然太大, 接着应用**流水线并行**, 跨节点增加阶段数, 直到整个模型可以被完全装入所有参与的 GPU 内存中.

2.  **目标二: 提升吞吐量 (Scale the throughput)**
    - **Step 3**: 在模型能装下的前提下, 利用集群中所有剩余的 GPU, 应用**数据并行**. 数据并行的副本数越多, 全局批次大小就可以越大, 从而提升整体的训练速度.

#### 4. 意义

3D 并行框架 (如 **[Megatron-LM](./Lecture7-Megatron-LM.md)**) 是当前训练最大规模语言模型 (数百亿到万亿参数) 的事实标准. 它提供了一个系统性的方法论, 将不同并行策略的优势在最适合它们的硬件层级上发挥出来, 实现了对计算、内存和通信资源的近乎最优的协同利用.