### 概念: ZeRO (Zero Redundancy Optimizer)

#### 1. 核心定义

ZeRO, 全称为零冗余优化器 (Zero Redundancy Optimizer), 是由微软 DeepSpeed 团队提出的一套旨在解决**[数据并行](./Lecture7-Data-Parallelism.md)**中内存冗余问题的优化技术. 与传统数据并行中每个 GPU 都存储完整的模型状态不同, ZeRO 通过对训练过程中的各种状态 (优化器状态、梯度、模型参数) 进行分片 (partitioning/sharding), 使得每个 GPU 只需存储其中的一部分, 从而在 N 个设备上将内存占用降低近 N 倍.

#### 2. ZeRO 的三个阶段

ZeRO 提供了一种渐进式的优化策略, 分为三个阶段, 可以根据需求逐步应用以获得更大的内存节省.

- **Stage 1: 优化器状态分片 (Optimizer State Partitioning)**:
    - **问题**: 在混合精度训练中, **[Adam 优化器](./Lecture7-Adam-Optimizer.md)**的状态 (如一阶矩、二阶矩和 FP32 主权重) 占用了大量的内存 (通常是模型参数的 8-12 倍). 在传统数据并行中, 这部分状态在每个 GPU 上都是完全重复的.
    - **解决方案**: ZeRO-1 将优化器状态在所有数据并行设备上进行分片. 每个 GPU 只负责存储和更新属于自己分片的那部分参数的优化器状态.
    - **实现技巧**: 利用了**[集体通信操作](./Lecture7-Collective-Communication.md)**中的 `All-Reduce ≡ Reduce-Scatter + All-Gather` 恒等式. 梯度同步时, 不再执行完整的 All-Reduce, 而是:
        1.  对梯度执行 `Reduce-Scatter`, 将全局梯度的不同分片聚合到各自负责的 GPU 上.
        2.  每个 GPU 使用本地的优化器状态分片, 更新自己负责的那部分模型参数.
        3.  执行 `All-Gather`, 将所有设备更新后的参数分片收集起来, 重建完整的模型以备下一次前向传播.
    - **效果**: 在通信成本几乎不变的情况下 (因此被称为“零开销”), 大幅减少了优化器状态的内存冗 ઉ余, 通常能节省 4 倍的内存.

- **Stage 2: 梯度分片 (Gradient Partitioning)**:
    - **问题**: 即使优化器状态被分片, 梯度 (通常与模型参数大小相同) 在每个 GPU 上仍然是完整的副本.
    - **解决方案**: 在 ZeRO-1 的基础上, 进一步对梯度进行分片. 在反向传播过程中, 梯度在计算出来后立即通过 `Reduce` 操作发送到对应的 GPU, 而不是在本地完整存储.
    - **效果**: 进一步节省了梯度存储的内存, 总内存节省可达 8 倍. 会引入少量同步开销.

- **Stage 3: 参数分片 (Parameter Partitioning)**:
    - **问题**: 模型参数本身在每个 GPU 上仍然是完整的副本.
    - **解决方案**: 终极分片策略. 将模型参数也进行分片. 在训练过程中, 任何时刻都没有任何一个 GPU 拥有完整的模型参数.
    - **工作流程**: 在前向或反向传播时, 每个 GPU 会在需要计算某一层之前, 动态地通过 `All-Gather` 从其他设备获取该层的参数. 计算完成后, 立即丢弃这些非本地的参数以释放内存.
    - **效果**: 实现了模型状态 (参数、梯度、优化器状态) 的完全分片, 内存节省与 GPU 数量成正比. 这种方案与 PyTorch 中的**[FSDP](./Lecture7-FSDP.md)**在思想上是等价的.

#### 3. 影响与意义

ZeRO 的出现是分布式训练领域的一个里程碑. 它极大地降低了训练超大型模型的硬件门槛, 使得在有限的 GPU 内存下训练千亿级别参数的模型成为可能. 它保留了数据并行易于使用的优点, 同时解决了其最致命的内存冗余问题, 成为了当今大规模模型训练事实上的标准技术之一.