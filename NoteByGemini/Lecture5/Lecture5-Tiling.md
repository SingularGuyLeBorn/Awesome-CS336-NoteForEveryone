### 1. 概念定义

**分块 (Tiling)**, 在 GPU 计算中也常被称为**线程块化 (Threading Blocking)**, 是一种核心的性能优化策略. 其基本思想是将一个大的计算问题(通常涉及大的数据集, 如矩阵)分解成许多小的、可以独立处理的**瓦片 (tiles)** 或 **块 (blocks)**, 然后将每个块的数据加载到 **[SM](./Lecture5-Streaming-Multiprocessor.md)** 的高速**[共享内存](./Lecture5-GPU-Memory-Hierarchy.md)**中进行计算. 

这种技术的目标是**最大化数据重用**, 从而**最小化对慢速全局内存的访问**. 

### 2. 为何需要分块？

在许多算法中, 尤其是像矩阵乘法这样的操作, 输入数据会被多次重复使用. 
- **非分块方法 (Naive Approach)**: 在一个朴素的实现中, 每次计算都需要从缓慢的全局内存中读取输入数据. 例如, 在计算 `C = A * B` 时, 矩阵 A 的每一行都需要与矩阵 B 的每一列进行点乘. 这意味着矩阵 A 的每个元素会被重复读取 N 次(N 是 B 的列数), 矩阵 B 的每个元素也会被重复读取 M 次(M 是 A 的行数). 所有这些重复读取都来自高延迟的全局内存, 导致严重的**[内存瓶颈](./Lecture5-Roofline-Model.md)**. 

- **分块方法 (Tiled Approach)**: 通过分块, 我们可以改变这种低效的访问模式. 整个计算过程被分解成一系列在小块上进行的矩阵乘法. 

### 3. 分块的工作原理:以矩阵乘法为例

以 **[分块矩阵乘法](./Lecture5-Tiled-Matrix-Multiplication-Algorithm.md)** 为例, 其工作流程如下:

1.  **分解**: 将输入矩阵 A 和 B, 以及输出矩阵 C, 都逻辑上划分为固定大小的子矩阵, 即“瓦片”. 
2.  **分配任务**: 将计算输出矩阵 C 的一个瓦片 `C_sub` 的任务分配给一个**[线程块](./Lecture5-GPU-Execution-Model.md)**. 
3.  **循环加载与计算**: 该线程块会进入一个循环. 在每次循环中:
    a.  线程块内的所有线程协同工作, 从全局内存中加载 A 的一个相关瓦片 `A_sub` 和 B 的一个相关瓦片 `B_sub` 到该线程块的**共享内存**中. 这个加载过程本身也需要被优化以实现**[内存合并](./Lecture5-Memory-Coalescing.md)**. 
    b.  在数据加载到共享内存后, 进行一次同步(`__syncthreads()`), 确保所有数据都已就绪. 
    c.  线程块内的每个线程从共享内存中读取 `A_sub` 和 `B_sub` 的元素, 进行计算, 并将结果累加到自己私有的**寄存器**中(用于存储 `C_sub` 的部分结果). 
4.  **写回结果**: 当所有相关的 A 和 B 瓦片都处理完毕后, 线程块内的每个线程将自己寄存器中累加的最终结果写回到全局内存中对应的 `C_sub` 位置. 

### 4. 优势与复杂性

**优势**:

- **极大地减少全局内存访问**: 输入矩阵 A 和 B 的每个元素只从全局内存中被读取一次, 加载到共享内存后, 会被该线程块内的所有线程重复使用多次. 这显著提高了程序的**算术强度**. 
- **利用高速内存**: 绝大部分计算都发生在 SM 内部, 数据在极速的共享内存和寄存器之间流动, 充分发挥了 GPU 的计算潜力. 

**复杂性**:

- **分块大小的选择**: 瓦片的大小是一个需要仔细权衡的参数. 它必须足够小, 以确保一个瓦片的数据能够完全放入 SM 有限的共享内存中; 但又需要足够大, 以提供足够的并行度和数据重用. 
- **边界处理**: 当矩阵的维度不能被分块大小整除时, 需要处理边界情况, 这会增加代码的复杂性. 
- **性能波动**: 如讲座所示, 不当的分块大小会导致**[波形量化](./Lecture5-Wave-Quantization.md)**和内存对齐问题, 从而引起剧烈的性能波动. 

总之, 分块是 GPU 编程中将算法从理论映射到高性能实现的最重要桥梁之一. 它通过显式地管理**[内存层级](./Lecture5-GPU-Memory-Hierarchy.md)**, 将数据流动的瓶颈降到最低, 是像 **[FlashAttention](./Lecture5-FlashAttention.md)** 等顶尖优化算法的基石. 