### 1. 概念定义

**控制流发散 (Control Divergence)**, 或称**线程束发散 (Warp Divergence)**, 是在 **[SIMT (单指令, 多线程)](./Lecture5-SIMT.md)** 执行模型(如 NVIDIA GPU)中发生的一种性能瓶颈. 它指的是在一个**[线程束 (Warp)](./Lecture5-GPU-Execution-Model.md)**(通常是 32 个线程)内, 由于条件语句(如 `if-else`), 不同的线程需要执行不同的指令路径. 

### 2. 发生原因与机制

GPU 硬件的设计基础是并行执行. 一个 **[SM](./Lecture5-Streaming-Multiprocessor.md)** 的调度器以 Warp 为单位分派指令, 在一个时钟周期内, 一个 Warp 中的所有 32 个线程必须执行**完全相同**的指令. 

当遇到条件分支时, 问题就出现了:
```c
if (threadIdx.x < 4) {
    // 路径 A
    do_A();
} else {
    // 路径 B
    do_B();
}
```

假设一个 Warp 内的线程 0-3 满足条件 `threadIdx.x < 4`, 而线程 4-31 不满足. 硬件无法同时执行 `do_A()` 和 `do_B()`. 为了维持 SIMT 模型, 硬件会采取以下**串行化 (Serialization)** 的方式处理:

1.  **执行路径 A**:
    - 硬件首先执行 `if` 分支(路径 A). 
    - 线程 0-3 变为**活动 (active)** 状态并执行 `do_A()`. 
    - 线程 4-31 变为**非活动 (inactive)** 状态, 它们被**屏蔽 (masked out)**, 在原地等待, 不执行任何操作. 

2.  **执行路径 B**:
    - 在路径 A 的所有指令执行完毕后, 硬件接着执行 `else` 分支(路径 B). 
    - 此时, 线程 0-3 变为非活动状态. 
    - 线程 4-31 变为活动状态, 并执行 `do_B()`. 

3.  **重新聚合**:
    - 在所有分支路径都执行完毕后, Warp 内的所有线程重新聚合, 继续执行分支之后的公共代码. 

### 3. 性能影响

控制流发散对性能的损害是显而易见的:

- **降低有效并行度**: 本来可以 32 个线程并行工作的 Warp, 现在变成了只有一小部分线程在工作, 而其他线程都在空闲等待. 在最坏的情况下(例如, 每个线程都走不同的复杂路径), 一个 Warp 的执行时间会是所有分支路径执行时间的总和, 并行优势几乎丧失. 
- **浪费计算资源**: 在任何一个时间点, SM 的计算单元(SPs)都只有一部分被利用, 因为大量的线程被屏蔽了. 

### 4. 如何避免或减轻

- **编写无分支代码**: 尽可能地将逻辑转化为不包含条件分支的数学运算. 例如, `if (x > 0) y = x; else y = 0;` 可以被替换为无分支的 `y = max(0, x);`. 
- **数据重排**: 如果可能, 在启动核函数之前对输入数据进行排序或分组, 使得同一个 Warp 内的线程更有可能满足相同的条件, 从而走向相同的执行路径. 
- **减少分支粒度**: 确保分支条件尽可能地在 Warp 级别上是一致的. 例如, 让整个 Warp 的线程根据一个共同的条件进行判断, 而不是每个线程独立判断. 

总之, 控制流发散是 SIMT 架构为了维持其简单的并行模型而付出的代价. 在编写高性能 GPU 代码时, 开发者必须时刻意识到 Warp 的存在, 并努力编写“Warp-friendly”的代码, 以最大限度地减少线程之间的行为差异. 