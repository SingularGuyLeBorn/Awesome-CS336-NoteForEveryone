### 1. 概念定义

**内存合并 (Memory Coalescing)** 是一种关键的 GPU 性能优化技术，它指的是当一个**[线程束 (Warp)](./Lecture5-GPU-Execution-Model.md)**（32个线程）中的所有线程同时访问**[全局内存](./Lecture5-GPU-Memory-Hierarchy.md)**时，硬件能够将这些离散的、独立的内存请求合并成一次或少数几次大的、连续的内存事务。

这个过程对程序员是透明的，但代码的内存访问模式直接决定了硬件能否成功进行合并，从而对性能产生巨大影响。

### 2. 背景：DRAM 的突发模式 (Burst Mode)

要理解内存合并，首先需要了解 DRAM（GPU 全局内存的基础）的工作方式。DRAM 的设计使得读取一个字节和读取一小段连续的字节（例如 32、64 或 128 字节）的成本相差无几。这是因为最耗时的步骤是定位到正确的内存行并将其内容复制到内部缓冲区（行缓冲）。一旦数据在缓冲区中，连续读取多个字节就非常快。

这种一次性读取一个连续数据块的机制被称为**突发模式 (Burst Mode)**。GPU 硬件正是利用这一特性来实现内存合并的。

### 3. 合并的条件与机制

当一个 Warp 中的 32 个线程发起内存读/写请求时，GPU 的内存控制器会检查这些请求的地址。

- **理想情况（完全合并）**:
    - 如果这 32 个线程访问的内存地址是**连续的**，并且**对齐**到一个突发事务的大小（例如 128 字节），那么硬件就可以将这 32 个请求合并成**一个单一的 128 字节内存事务**。
    - 这时，内存带宽的利用率是最高的。例如，如果每个线程读取 4 字节（一个 `float`），32 个线程总共需要 128 字节。一次 128 字节的事务就能满足所有线程的需求。

- **次优情况（部分合并）**:
    - 如果访问的地址是连续的，但跨越了两个突发事务的边界，硬件会发起两次内存事务。
    - 如果访问的地址不连续，但在一个较小的地址范围内，硬件可能会通过几次事务来满足所有请求。

- **最坏情况（不合并）**:
    - 如果 32 个线程访问的地址是完全随机、分散的，那么硬件可能需要为每个线程（或每几个线程）都发起一次独立的内存事务。这会导致总共需要执行多达 32 次内存事务，内存效率极低，性能急剧下降。

### 4. 实践中的重要性

在编写 CUDA 代码时，内存访问模式至关重要。

- **行主序 vs. 列主序**: 如讲座中的矩阵乘法示例所示，当处理一个以行主序存储的二维矩阵时：
    - **让线程沿行读取（Coalesced）**: 如果 Warp 内的线程 0, 1, 2, ... 分别读取 `matrix[row][0]`, `matrix[row][1]`, `matrix[row][2]`, ...，那么它们的内存地址是连续的，访问可以被完全合并。
    - **让线程沿列读取（Not Coalesced）**: 如果 Warp 内的线程 0, 1, 2, ... 分别读取 `matrix[0][col]`, `matrix[1][col]`, `matrix[2][col]`, ...，那么它们的内存地址会相隔一个行宽（`WIDTH`），地址是分散的，无法合并。

- **分块技术与合并**: **[分块 (Tiling)](./Lecture5-Tiling.md)** 技术不仅利用了共享内存，在从全局内存向共享内存加载数据时，也必须精心设计加载模式，以确保加载过程是合并的，从而最大化数据从慢速内存到快速内存的传输效率。

总之，内存合并是 GPU 硬件为了掩盖高延迟全局内存而提供的一种强大优化机制。编写高性能 GPU 代码的开发者必须时刻将“合并访问”作为一项基本原则，确保数据布局和线程访问模式能够最大化地利用这一硬件特性。