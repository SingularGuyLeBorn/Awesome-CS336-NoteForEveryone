### 1. 概念定义

**SIMT (Single Instruction, Multiple Threads)**, 即**单指令, 多线程**, 是现代 **[GPU](./Lecture5-GPU-Architecture.md)** 所采用的核心执行模型. 它结合了传统并行计算中 SIMD (Single Instruction, Multiple Data) 模型的思想, 但提供了更灵活的编程抽象. 

在 SIMT 模型下, GPU 的硬件调度器将一条指令广播给一组线程(一个**[线程束, Warp](./Lecture5-GPU-Execution-Model.md)**), 这组线程会**同时**执行这条相同的指令, 但每个线程都在自己**私有**的数据上进行操作. 

### 2. 与 SIMD 的对比

要理解 SIMT, 最好先了解它的前身 SIMD. 

- **SIMD (单指令, 多数据)**:
    - **模型**: 一条指令同时作用于一个数据向量(vector)中的所有元素. 
    - **硬件实现**: 通常由专门的向量处理器或 CPU 中的向量指令集(如 SSE, AVX)实现. 
    - **编程**: 程序员需要显式地将数据打包成向量, 并使用向量指令进行操作. 这被称为“向量化”, 管理起来较为繁琐. 
    - **示例**: `vector_add(vector_A, vector_B)`, 一条指令完成两个向量的逐元素相加. 

- **SIMT (单指令, 多线程)**:
    - **模型**: 提供了一个更通用的标量编程模型. 程序员编写的是针对**单个线程**的代码, 就好像它是一个普通的串行程序一样. 
    - **硬件实现**: 硬件(**[SM](./Lecture5-Streaming-Multiprocessor.md)** 的调度器)负责将这些独立的标量线程分组到 Warp 中, 并将它们的执行“向量化”. 当一个 Warp 被调度时, 硬件提取出当前要执行的指令, 并让 Warp 内的 32 个线程在各自的数据上并行执行. 
    - **编程**: 程序员无需关心数据的向量化. 他们只需要启动大量的线程, 并使用线程 ID (`threadIdx`) 来区分每个线程应该处理的数据. 这种抽象极大地简化了并行编程. 

**核心区别**: SIMT 是一个**执行模型**, 它将程序员编写的独立标量线程, 在硬件层面以 SIMD 的方式高效执行. 它为程序员隐藏了向量化的复杂性. 

### 3. SIMT 的优势与挑战

**优势**:

- **编程简单性**: 程序员可以专注于单个线程的逻辑, 而不需要手动管理数据向量. 这使得编写复杂的并行程序变得更加容易和直观. 
- **灵活性**: 每个线程都有自己的指令地址计数器和寄存器状态, 这使得处理更复杂的逻辑成为可能, 例如, 每个线程可以独立地进行内存寻址. 

**挑战**:

- **[控制流发散 (Control Divergence)](./Lecture5-Control-Divergence.md)**: 这是 SIMT 模型最大的挑战. 如果一个 Warp 内的线程因为条件分支而需要执行不同的代码路径, 硬件必须串行化这些路径, 导致部分线程闲置, 从而损失并行效率. 这是 SIMD 模型中不存在的问题, 因为向量中的所有元素必须遵循相同的控制流. 

### 4. 总结

SIMT 是 GPU 能够在保持相对简单的编程模型的同时, 实现大规模并行计算的关键. 它巧妙地将并行性的管理从程序员转移到了硬件层面. 通过理解 SIMT 的工作原理, 特别是其核心单位——Warp 的行为, 开发者才能编写出能够避免其陷阱(如控制流发сан)并充分利用其优势(如**[内存合并](./Lecture5-Memory-Coalescing.md)**)的高性能代码. 