### 1. 概念定义

**GPU 内存层级 (GPU Memory Hierarchy)** 指的是 GPU 内部和外部各种存储单元的组织结构。这个结构是一个金字塔模型，其顶端是速度最快、容量最小、最接近计算单元的内存，底端则是速度最慢、容量最大、距离最远的内存。

理解并有效利用这个内存层级，是编写高性能 GPU 程序、避免**[内存瓶颈](./Lecture5-Roofline-Model.md)** 的核心所在。内存访问的速度差异极大，最高和最低层级之间可能存在数百倍的延迟差距。

### 2. 内存层级的结构

从快到慢，从内到外，典型的 GPU 内存层级包括以下几个部分：

1.  **寄存器 (Registers)**:
    - **位置**: 位于 **[SM](./Lecture5-Streaming-Multiprocessor.md)** 内部。
    - **特性**: 速度最快（约 1 个时钟周期延迟），是 GPU 中最快的存储单元。
    - **作用域**: 每个**[线程](./Lecture5-GPU-Execution-Model.md)**拥有自己私有的一组寄存器，用于存储局部变量。
    - **访问**: 只能被其所属线程访问。

2.  **L1 缓存 (L1 Cache) / 共享内存 (Shared Memory)**:
    - **位置**: 位于 **SM** 内部，是高速的片上 SRAM。
    - **特性**: 访问速度极快（约 20-30 个时钟周期延迟），远快于全局内存。
    - **作用域**:
        - **共享内存**: 由一个**[线程块](./Lecture5-GPU-Execution-Model.md)**内的所有线程共享。程序员可以显式地控制其读写。
        - **L1 缓存**: 对全局内存的访问进行缓存，对程序员透明。
    - **用途**: 共享内存是实现高性能的关键，用于线程间的快速数据交换和缓存从全局内存中加载的数据块（即**[分块技术 (Tiling)](./Lecture5-Tiling.md)**）。

3.  **L2 缓存 (L2 Cache)**:
    - **位置**: 位于 GPU 芯片上，但在 SM 外部。
    - **特性**: 容量比 L1 缓存大，但速度稍慢（约 200-300 个时钟周期延迟）。
    - **作用域**: 被 GPU 上所有的 SM 共享。
    - **用途**: 作为全局内存的最后一级缓存，对程序员透明，帮助缓解对全局内存的访问压力。

4.  **全局内存 (Global Memory)**:
    - **位置**: 位于 GPU 芯片外部，通常是独立的 **[高带宽内存 (HBM)](./Lecture5-High-Bandwidth-Memory-HBM.md)** 或 GDDR 显存芯片。
    - **特性**: 容量最大（GB 级别），但速度最慢，延迟最高（数百个时钟周期）。
    - **作用域**: 可被所有 SM 上的所有线程访问，也可被主机（CPU）访问。
    - **用途**: 存储主要的输入数据、模型参数和输出结果。所有跨线程块的通信都必须通过全局内存进行。

### 3. 重要性与优化策略

内存层级的设计直接影响了 GPU 编程的策略：

- **数据局部性原则**: 高性能代码的核心是最大化数据局部性，即尽可能将计算所需的数据保留在靠近计算单元的高速内存中（寄存器、共享内存）。
- **减少全局内存访问**: 访问全局内存是 GPU 计算中最昂贵的操作之一。优化的首要目标就是**最小化全局内存的读写次数**。
- **利用层级进行优化**:
    - **[分块技术 (Tiling)](./Lecture5-Tiling.md)**: 将数据从全局内存一次性加载一个“块”到共享内存，然后在共享内存中进行大量计算，最后将结果写回。这摊销了昂贵的全局内存访问成本。
    - **[内存合并 (Memory Coalescing)](./Lecture5-Memory-Coalescing.md)**: 即使必须访问全局内存，也要确保一个 **Warp** 内的线程以连续、对齐的方式进行访问，以触发硬件的合并读取机制，提高有效带宽。

如讲座中所强调的，现代 GPU 的计算能力增长速度远超内存带宽，使得“内存墙”问题日益突出。因此，深刻理解并围绕 GPU 内存层级进行算法设计和代码优化，是释放 GPU 全部潜能的关键。