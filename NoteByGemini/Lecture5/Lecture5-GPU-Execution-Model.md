### 1. 概念定义

**GPU 执行模型 (GPU Execution Model)** 描述了 GPU 如何组织和执行大规模并行任务. 这个模型是一个层次化的结构, 旨在将一个庞大的计算问题分解成数百万个可以由 GPU 硬件高效处理的微小任务. 在 NVIDIA 的 **[CUDA](./Lecture5-CUDA.md)** 编程环境中, 这个模型由三个核心概念组成:**线程 (Threads)**、**线程块 (Blocks)** 和 **线程束 (Warps)**. 

### 2. 核心层次结构

1.  **线程 (Thread)**:
    - **定义**: 执行计算的最基本单位. 每个线程都执行相同的核函数代码 (kernel code), 但通常处理不同的数据. 
    - **特性**: 每个线程拥有自己私有的**寄存器 (Registers)** 来存储局部变量, 并且有一个唯一的标识符(`threadIdx`)来区分它在线程块中的位置. 

2.  **线程块 (Block)**:
    - **定义**: 一组线程的集合, 它们可以相互协作. 一个线程块内的线程可以同步, 并且可以通过高速的**[共享内存](./Lecture5-GPU-Memory-Hierarchy.md)**来共享数据. 
    - **调度**: 整个线程块被作为一个单元, 调度到单个**[流式多处理器 (SM)](./Lecture5-Streaming-Multiprocessor.md)** 上执行. 这意味着一个块的生命周期完全在一个 SM 内部, 保证了共享内存的私有性和高速访问. 
    - **协作**: 这是 CUDA 编程中线程协作的主要层次. 例如, 在进行**[分块矩阵乘法](./Lecture5-Tiled-Matrix-Multiplication-Algorithm.md)**时, 一个线程块负责计算输出矩阵的一个子块. 

3.  **网格 (Grid)**:
    - **定义**: 一组线程块的集合. 一个核函数的启动(launch)会生成一个网格. 
    - **独立性**: 不同线程块之间是相互独立的, 它们不能直接通信或同步. 任何跨块的通信都必须通过缓慢的**全局内存**来间接进行. 这种设计保证了极高的可扩展性, 因为 GPU 可以以任意顺序、在任意可用的 SM 上执行网格中的所有线程块. 

### 3. 硬件执行单位:线程束 (Warp)

虽然程序员在逻辑上是以线程和线程块来思考, 但 GPU 硬件的实际执行单位是 **线程束 (Warp)**. 

- **定义**: 一个 Warp 是一个包含 32 个连续线程的组. 
- **调度单元**: **[SM](./Lecture5-Streaming-Multiprocessor.md)** 的调度器是以 Warp 为单位来分派指令的. 在一个时钟周期内, 一个 Warp 中的 32 个线程会同时执行**完全相同**的指令, 这就是 **[SIMT (单指令, 多线程)](./Lecture5-SIMT.md)** 模型的体现. 
- **性能影响**: Warp 的存在对性能有深远影响:
    - **[控制流发散](./Lecture5-Control-Divergence.md)**: 如果一个 Warp 内的线程在 `if-else` 语句中走向了不同的分支, 硬件会串行化地执行每个分支路径, 而让不执行该路径的线程处于闲置状态, 从而导致性能下降. 
    - **[内存合并](./Lecture5-Memory-Coalescing.md)**: 当一个 Warp 中的所有线程访问全局内存时, 如果它们的访问地址是连续且对齐的, 硬件可以将这 32 次独立的访问合并成一次或几次大的事务, 极大地提高了内存带宽利用率. 

### 4. 总结

- **程序员视角 (逻辑模型)**: Grid > Block > Thread
- **硬件视角 (执行模型)**: SM 调度 Block -> Block 内的 Warps 被调度 -> Warp 内的 32 个 Threads 同时执行一条指令

这个执行模型的设计精髓在于, 它通过一个清晰的层次结构, 将大规模并行问题映射到硬件上, 同时为程序员提供了控制数据局部性(通过 Block 和 Shared Memory)和利用硬件特性(通过 Warp 实现内存合并)的手段, 从而实现了在可扩展性和高性能之间的平衡. 