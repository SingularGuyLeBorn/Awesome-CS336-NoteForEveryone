### 1. 概念定义

**流式多处理器 (Streaming Multiprocessor, SM)** 是 NVIDIA GPU 架构中的核心构建块和基本调度单位。可以将其理解为 GPU 内部的一个独立的“微型处理器”，整个 GPU 的强大并行计算能力正是通过集成数十个乃至上百个这样的 SM 来实现的。

每个 SM 负责执行被分配给它的**[线程块 (Blocks)](./Lecture5-GPU-Execution-Model.md)**，并管理其内部的计算资源和内存资源。

### 2. SM 的内部结构

一个 SM 是一个高度复杂的单元，其内部集成了多种关键组件，以协同工作，实现高效的并行计算：

1.  **流式处理器 (Streaming Processors, SPs)** 或 **CUDA 核心**:
    - 这是最基本的计算单元，负责执行整数和浮点数运算。每个 SM 内部都包含大量的 SPs（例如，一个 A100 的 SM 中有 64 个 FP32 SP）。
    - 它们是 **[SIMT (单指令，多线程)](./Lecture5-SIMT.md)** 执行模型的基础，由 SM 的调度器统一分派指令。

2.  **张量核心 (Tensor Cores)**:
    - 从 Volta 架构开始引入的专用硬件单元，专门用于加速混合精度的矩阵乘法累加（Matrix Multiply-Accumulate, MMA）运算。
    - **[张量核心](./Lecture5-Tensor-Cores.md)** 对深度学习的性能提升至关重要，因为神经网络中的绝大部分计算都是矩阵乘法。它们可以在一个时钟周期内完成一个小的矩阵乘法，效率远高于通用的 SP。

3.  **调度器 (Warp Scheduler)**:
    - SM 的“大脑”，负责管理和调度其内部的**[线程束 (Warps)](./Lecture5-GPU-Execution-Model.md)**。
    - 调度器选择准备就绪的 Warp，并将指令分派给 SPs 或 Tensor Cores 执行。这种设计使得 GPU 能够有效地隐藏内存访问延迟：当一个 Warp 因为等待数据而停顿时，调度器可以立即切换到另一个准备就绪的 Warp，从而保持计算单元的繁忙。

4.  **共享内存 (Shared Memory) 和 L1 缓存**:
    - 每个 SM 都拥有自己私有的一块高速片上内存，即**[共享内存](./Lecture5-GPU-Memory-Hierarchy.md)**。
    - 它的访问速度与寄存器相当，远快于全局内存。同一线程块内的所有线程可以共享这块内存，用于线程间的快速数据交换和缓存频繁访问的数据。
    - **[分块技术 (Tiling)](./Lecture5-Tiling.md)** 的核心就是将数据从慢速的全局内存加载到 SM 的快速共享内存中进行计算。

5.  **寄存器文件 (Register File)**:
    - 每个 SM 都有一个大型的寄存器文件，供其内部的所有线程使用。寄存器是 GPU 中最快的存储单元，每个线程都有自己私有的寄存器来存储局部变量。

### 3. 在 GPU 架构中的角色

- **并行化的基本单位**: GPU 的总计算能力可以通过简单地增加 SM 的数量来扩展。一个有 128 个 SM 的 GPU，理论上可以同时处理 128 个独立的线程块。
- **任务调度的边界**: 在 **[CUDA](./Lecture5-CUDA.md)** 编程模型中，一个线程块被保证会在单个 SM 上从头到尾执行完毕。这意味着线程块是程序员能够直接控制数据局部性（通过共享内存）的最高层次。
- **资源分配的核心**: SM 是 GPU 资源（如共享内存、寄存器）分配的基本单位。一个 SM 能同时驻留的线程块和 Warp 的数量，取决于这些块和 Warp 对 SM 内部资源的需求。

理解 SM 的结构和功能，是理解 GPU 如何实现大规模并行、如何隐藏延迟以及如何进行性能优化的基础。所有高级的优化技巧，最终都是为了更好地适应 SM 的工作方式。