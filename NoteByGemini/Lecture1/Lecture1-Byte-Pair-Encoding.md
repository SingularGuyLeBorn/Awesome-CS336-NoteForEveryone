# 专题：字节对编码 (Byte-Pair Encoding, BPE)
## 1. 核心思想
字节对编码（Byte-Pair Encoding, BPE）是一种简单而高效的数据压缩算法，后来被广泛应用于自然语言处理领域，成为构建子词（subword）词汇表的主流方法之一。
其核心思想是：**从一个基础的单元词汇表（如字符或字节）开始，通过迭代地查找并合并数据中出现频率最高的一对相邻单元，来逐步构建一个更大的、包含复合单元的词汇表。**
在 NLP 的语境下，BPE 能够自适应地学习出一种**[Tokenization](./Lecture1-Tokenization.md)**方案，使得：
*   **常见词**（如 "hello", "world"）被表示为单个 token。
*   **罕见词**（如 "tokenization"）被拆分成多个有意义的子词单元（如 "token", "ization"）。
*   **未知词**（如 "Supercalifragilisticexpialidocious"）也能被拆分成更小的单元，从而完美地解决了未登录词（OOV）问题。
## 2. 算法描述（训练过程）
BPE 词汇表的构建过程如下：
1.  **准备数据和初始词汇表:**
    *   获取一个大的文本语料库。
    *   定义一个初始的基础词汇表。在现代**[语言模型](./Lecture1-Language-Models.md)**中，这个基础词汇表通常是全部 256 个字节（bytes）。这样做的好处是，任何文本字符串都可以被无损地表示为字节序列，从而天然地避免了处理未知字符的问题。
    *   将语料库中的所有文本分割成基础词汇表中的单元序列。例如，"hello" -> `['h', 'e', 'l', 'l', 'o']`。
2.  **迭代合并:**
    *   **循环**指定的次数（这个次数决定了最终词汇表的大小）：
        a. **统计频率:** 在当前的文本数据中，统计所有相邻 token 对的出现频率。例如，在 `['h', 'e', 'l', 'l', 'o']` 中，相邻对有 `('h', 'e')`, `('e', 'l')`, `('l', 'l')`, `('l', 'o')`。
        b. **找到最高频对:** 找出出现次数最多的那一对，例如 `('e', 's')` 在语料库中出现了 1000 次，是所有对中最高的。
        c. **合并:** 创建一个新的 token，代表这个最高频对。例如，创建一个新 token `'es'`。将这个合并规则（`('e', 's') -> 'es'`）记录下来。
        d. **更新数据:** 在整个语料库中，将所有出现的 `('e', 's')` 替换为新的 token `'es'`。
3.  **完成:** 当循环结束后，最终的词汇表就由初始的 256 个字节加上所有通过合并生成的新 token 组成。合并规则的集合（按生成顺序列出）就是训练好的 BPE 模型。
## 3. 编码与解码过程
*   **编码 (Encoding):**
    1.  将新的输入字符串转换为字节序列。
    2.  按照训练时学到的**合并规则的顺序**，贪婪地在字节序列上进行合并操作。例如，如果合并规则有 `(e, s) -> es` 和 `(es, t) -> est`，会先应用 `(e, s) -> es`，然后再看是否有机会应用 `(es, t) -> est`。
    3.  当无法再进行任何合并时，得到的 token 序列就是编码结果。
*   **解码 (Decoding):**
    *   解码过程非常简单，只需将所有 token 替换回它们所代表的字节序列，然后将字节序列拼接起来，最后用 UTF-8 解码回字符串即可。
## 4. 优缺点分析
*   **优点:**
    *   **无 OOV 问题:** 由于底层是字节，任何字符串都能被处理。
    *   **压缩效率高:** 能够有效平衡词汇表大小和序列长度。
    *   **算法简单:** 易于理解和实现。
*   **缺点:**
    *   **贪婪性:** BPE 是一个贪婪算法，它每次都选择当前最优的合并，但这并不保证全局最优。例如，对于 "ironman"，如果 "on" 的频率高于 "ir"，它可能会先合并 "on"，导致无法形成 "iron"。
    *   **依赖预切分:** 在实际应用中（如 **[GPT-2](./Lecture1-GPT-4.md)**），BPE 通常在一个经过预切分（pre-tokenization）的文本上运行，这使得 tokenizer 的行为对预切分的规则非常敏感。例如，"hello." 和 "hello ." 可能会被编码成完全不同的 token 序列。
尽管存在一些缺点，BPE 及其变体（如 WordPiece, Unigram）仍然是目前构建高效、鲁棒的 Tokenizer 的基石技术。