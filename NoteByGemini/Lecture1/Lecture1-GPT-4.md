# 专题: GPT-4
## 1. 核心贡献
GPT-4(Generative Pre-trained Transformer 4)是 OpenAI 于 2023 年 3 月发布的第四代大规模**[语言模型](./Lecture1-Language-Models.md)**. 它代表了当时**[开放与闭源模型](./Lecture1-Open-vs-Closed-Models.md)**生态中闭源模型的性能巅峰,并在通用智能方面取得了显著的飞跃. 
GPT-4 的核心贡献在于其**前所未有的强大通用能力和多模态能力**. 它在各种专业和学术基准测试上表现出与人类水平相当甚至超越人类的性能. 
## 2. 模型/方法概述
OpenAI 对 GPT-4 的技术细节披露得非常有限,遵循了其自 GPT-2 以来日益保密的策略. 然而,根据官方发布的技术报告、公开信息以及行业分析,我们可以推断出其关键特征: 
*   **巨大的规模:**
    *   据传闻,GPT-4 可能是一个**[混合专家模型 (MoE)](./Lecture1-Mixture-of-Experts.md)**,总参数量高达约 1.8 万亿(1.8T),由 16 个专家(每个约 111B 参数)组成. 
    *   在推理时,每个 token 的前向传播只会激活其中的 2 个专家,这使得其推理计算量(FLOPs)与一个约 280B 参数的密集模型相当,而不是 1.8T. 这是一种以增加参数量来换取更高性能,同时保持推理成本可控的有效策略. 
*   **大规模、高质量的数据:**
    *   GPT-4 的训练数据量远超 GPT-3,并且经过了更精细的筛选和清洗. 除了海量的公开网络数据,据信还包括了大量的书籍、代码以及高质量的专有数据集. 
*   **更强大的对齐技术:**
    *   GPT-4 在对齐方面投入了大量资源,包括更复杂的**[从人类反馈中强化学习 (RLHF)](./Lecture1-RLHF.md)** 流程. OpenAI 在模型训练中加入了额外的安全奖励信号,以减少有害或不希望的输出. 这使得 GPT-4 在遵循指令的准确性、事实性和安全性方面比前代模型有了巨大提升. 
*   **多模态能力:**
    *   GPT-4 是一个原生的多模态模型,能够同时处理文本和图像输入. 用户可以输入一张图片,并就图片内容进行提问或要求描述,模型能够理解图像中的物体、场景和关系,并生成相关的文本回答. 这是其相较于 GPT-3.5 的一个重大进步. 
## 3. 关键结果
*   **在标准化考试中的卓越表现:** GPT-4 在多种模拟考试中取得了惊人的成绩,例如在美国律师资格考试(Uniform Bar Exam)中取得了前 10% 的高分,在生物奥林匹克竞赛中取得了前 1% 的分数. 
*   **专业能力:** 在医学、法律、金融等专业领域的知识问答和推理任务中,展现出接近甚至超越专家的水平. 
*   **降低“幻觉”:** 相比前代模型,GPT-4 产生事实性错误的频率显著降低(减少了约 40%). 
*   **更长的上下文窗口:** GPT-4 提供了不同版本的上下文窗口,包括 8k 和 32k token,最新的 GPT-4 Turbo 版本更是支持 128k 的超长上下文,使其能够处理和理解整本书籍长度的文档. 
## 4. 影响力与局限性
*   **影响力:**
    *   **定义了新的性能基准:** GPT-4 的发布为整个 AI 行业设立了新的性能标杆,成为所有其他模型(无论是开放还是闭源)追赶和比较的对象. 
    *   **加速了 AI 应用的落地:** 其强大的通用能力使得构建复杂的、实用的 AI 应用变得更加容易,催生了大量基于 GPT-4 的初创公司和产品. 
    *   **引发了对 AGI 的广泛讨论:** GPT-4 所展现出的通用智能水平,使得关于通用人工智能(AGI)的讨论从遥远的未来想象变为了一个近在眼前的现实议题. 
*   **局限性:**
    *   **仍然存在“幻觉”:** 尽管有所改善,GPT-4 仍然会编造事实,在回答中出现错误. 
    *   **知识截止日期:** 其知识被限制在训练数据的时间范围内,无法获取实时的信息. 
    *   **推理能力有限:** 对于需要复杂、多步、符号化推理的问题,其表现仍不稳定. 
    *   **高昂的成本与能源消耗:** 训练和运行 GPT-4 这样的模型需要巨大的计算资源和能源,带来了环境和成本方面的挑战. 
---
**官方链接:** [GPT-4 Technical Report](https://arxiv.org/abs/2303.08774)