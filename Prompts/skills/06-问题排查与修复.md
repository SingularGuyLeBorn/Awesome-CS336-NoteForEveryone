# 技能：问题排查与修复

## 核心原则

> **先定位，再修复**：不要盲目尝试，先搞清楚问题的根本原因。

---

## 一、常见问题分类

### 1.1 链接类问题
- 图片链接 404
- 外部网页失效
- 相对路径错误

### 1.2 内容类问题
- 公式渲染失败
- 格式显示异常
- 中英文乱码

### 1.3 结构类问题
- 目录层级混乱
- 文件命名不规范
- 交叉引用断裂

---

## 二、图片链接修复流程

### Step 1: 问题识别
```bash
# 列出所有图片引用
grep -r "!\[" NoteByHuman/LectureX/*.md

# 检查本地图片是否存在
ls -la NoteByHuman/LectureX/images/
```

### Step 2: 原因诊断

| 现象 | 可能原因 | 检查方法 |
|------|----------|----------|
| 图片显示为空白 | 路径错误 | 检查相对路径 |
| 下载的图片很小 | 下载的是 404 页面 | 检查文件内容 |
| 外部图片失效 | 源站变更 | 访问原始 URL |

### Step 3: 修复策略

**策略 A: 找替代源**
```bash
# 搜索替代图片
# "[概念名] architecture diagram site:github.com"
```

**策略 B: 本地化**
```python
# 下载到本地
import requests
response = requests.get(url)
with open('images/local.png', 'wb') as f:
    f.write(response.content)
```

**策略 C: AI 生成**
```
使用 generate_image 工具，提供详细的技术描述 prompt
```

**策略 D: 文字替代**
```markdown
<!-- 原图失效，用文字描述替代 -->
> **[图片描述]**: 该图展示了 A 到 B 的转换过程...
```

---

## 三、外部链接修复流程

### Step 1: 检测失效链接
```python
import requests

def check_url(url):
    try:
        response = requests.head(url, timeout=10, allow_redirects=True)
        return response.status_code == 200
    except:
        return False
```

### Step 2: 修复策略

**策略 A: Wayback Machine**
```
https://web.archive.org/web/[原始URL]
```

**策略 B: 找官方替代**
- 论文: arxiv.org, openreview.net
- 代码: GitHub 原仓库或 fork
- 博客: 作者新地址

**策略 C: 转为引用**
```markdown
<!-- 原链接失效 -->
如 Smith et al. (2023) 所述: "[引用关键内容]"
```

---

## 四、Markdown 渲染问题

### 4.1 公式不渲染

**问题**: `$E=mc^2$` 显示为纯文本

**检查**:
- 渲染器是否支持 LaTeX
- 公式前后是否有空格
- 是否用错了 `$` 和 `$$`

**解决**:
```markdown
行内公式: $E = mc^2$ (两边加空格)
块级公式: 
$$
E = mc^2
$$
(上下留空行)
```

### 4.2 表格不对齐

**问题**: 表格列错位

**检查**:
- 分隔符 `|` 数量是否一致
- 是否有特殊字符干扰

**解决**:
```markdown
| 列1 | 列2 | 列3 |
|-----|-----|-----|
| a   | b   | c   |
```

### 4.3 代码块语法高亮失效

**问题**: 代码没有颜色

**检查**:
- 是否指定了语言
- 语言名称是否正确

**解决**:
```markdown
```python  ← 指定语言
def hello():
    print("Hello")
```　
```

---

## 五、排查工具箱

### 5.1 文件检查脚本

```python
import os
import re

def check_markdown_health(md_file):
    issues = []
    
    with open(md_file, 'r', encoding='utf-8') as f:
        content = f.read()
        lines = content.split('\n')
    
    # 检查图片链接
    img_pattern = r'!\[.*?\]\((.*?)\)'
    for match in re.finditer(img_pattern, content):
        img_path = match.group(1)
        if img_path.startswith('./') or img_path.startswith('../'):
            full_path = os.path.join(os.path.dirname(md_file), img_path)
            if not os.path.exists(full_path):
                issues.append(f"Missing image: {img_path}")
    
    # 检查标题层级
    prev_level = 0
    for i, line in enumerate(lines):
        if line.startswith('#'):
            level = len(line) - len(line.lstrip('#'))
            if level > prev_level + 1:
                issues.append(f"Line {i+1}: Heading level jump from {prev_level} to {level}")
            prev_level = level
    
    return issues
```

### 5.2 批量链接检查

```python
import requests
import re

def check_all_links(md_file):
    with open(md_file, 'r', encoding='utf-8') as f:
        content = f.read()
    
    # 提取所有 URL
    url_pattern = r'https?://[^\s\)>]+'
    urls = re.findall(url_pattern, content)
    
    results = []
    for url in urls:
        try:
            response = requests.head(url, timeout=5)
            status = "✅" if response.status_code == 200 else f"❌ {response.status_code}"
        except Exception as e:
            status = f"❌ {str(e)[:30]}"
        results.append((url[:50], status))
    
    return results
```

---

## 六、问题修复检查清单

### 修复前
- [ ] 确认问题的具体表现
- [ ] 记录原始状态 (截图/git stash)
- [ ] 分析根本原因

### 修复中
- [ ] 一次只改一个问题
- [ ] 每改一步验证效果
- [ ] 记录修改内容

### 修复后
- [ ] 验证问题已解决
- [ ] 检查没有引入新问题
- [ ] 提交并写清楚 commit 信息

---

## 七、预防性措施

### 7.1 图片本地化策略
- 所有关键图片下载到本地
- 外部链接仅作为备注

### 7.2 链接定期检查
```bash
# 每月运行一次链接检查
python scripts/check_links.py NoteByHuman/
```

### 7.3 内容备份
- 重要内容同步到多处
- Git 保持频繁提交
- 考虑使用 Git LFS 管理大文件
